{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "ME781-DATASCALES.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKAB0Tn8VEhb"
      },
      "source": [
        "## ME 781  (Data Scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGxp6RvmVEhd"
      },
      "source": [
        "### Following tasks in sequence:\n",
        "\n",
        "1. Create a list of 5 open data sets available for machine learning along with their links for each of the three Data Types (Discrete data Type, Sequential (temporal) data Type and Spatial data Type)\n",
        "\n",
        "\n",
        "2. Write a python code to input a dataset (csv file) of Discrete data type, automatically identify and print the\n",
        "\n",
        "    a. Number of attributes and number of entries\n",
        "    \n",
        "    b. Data scale of each attribute\n",
        "    \n",
        "    c. Data value of each attribute\n",
        "\n",
        "\n",
        "3.      Write a python code to perform statistics on each data column based on its data scale.\n",
        "\n",
        "\n",
        "4.      Can we use a box plot for visualizing ordinal data? (Yes/No). Explain why. \n",
        "\n",
        "![MicrosoftTeams-image2.png](attachment:MicrosoftTeams-image2.png)\n",
        "\n",
        "\n",
        "5.      Write a python code to visualize data in the csv file (a generalized method depending upon data scale) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8gR62WVEhd"
      },
      "source": [
        "  ###  We have a software to check plagiarism in code, if anyone found copying the code, strict action will be taken against such students and can also be given FR grade directly.\n",
        "    \n",
        "  We  expect  you  to  upload  colab  notebooks  when  you  are  required  to  turn  your  programming assignments.  Please  make  sure  that  you  provide  enough  comments  in  the  code  for  the TAs to understand \n",
        "       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnDZFi_gVEhe"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwF7nGfsVEhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f94d4894-37fe-4c56-903d-7b4c97608745"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "from pandas.api.types import is_string_dtype\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QLXktCMVEhh"
      },
      "source": [
        "### 1. List of 5 open data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzf7eBvvVrjt"
      },
      "source": [
        "Discrete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uad_unLtVEhi"
      },
      "source": [
        "## Paste the URLs of open datasets here and add comments describing the dataset\n",
        "url1 = \"https://www.kaggle.com/vikasojha98/top-women-chess-players\" \n",
        "# Top women chess players; Contains details of Top women chess players in the world sorted by \n",
        "# their Standard FIDE rating (highest to lowest above 1800 Elo) as updated in August 2020\n",
        "\n",
        "url2 = \"https://www.kaggle.com/vidyapb/indian-school-education-statistics\" \n",
        "# Contains information about Indian School Education Statistics of the year 2013-2014 to 2015-2016. \n",
        " # This dataset contains 7 files in .csv format about Percentage of Schools with Drinking Water Facility, Drop-out rate etc\n",
        "\n",
        "url3 = \"https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results\" \n",
        "# This is a historical dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2016.\n",
        " # Contains 271116 rows and 15 columns. Each row corresponds to an individual athlete competing in an individual Olympic event \n",
        "\n",
        "url4 = \"https://www.kaggle.com/christianlillelund/passenger-list-for-the-estonia-ferry-disaster\"\n",
        "# The full list of all passengers and crew members aboard the MS Estonia. Interesting things to investigate about the data:\n",
        "# Who's more likely to survive the sinking based on data? Is age an indicator for survival?\n",
        "\n",
        "url5 = \"https://www.kaggle.com/neuromusic/avocado-prices\"\n",
        "# Historical data on avocado prices and sales volume in multiple US markets\n",
        "# Some relevant columns in the dataset: Date - The date of the observation, AveragePrice - the average price of a single avocado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpXi5_nMVtct"
      },
      "source": [
        "Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xzt_Ys4VqAD"
      },
      "source": [
        "url1 = \"http://faculty.nps.edu/cmartell/NPSChat.htm\" # \tPosts from age-specific online chat rooms, \n",
        "#The NPS Chat Corpus, Release 1.0 consists of 10,567 posts out of approximately 500,000 posts\n",
        "\n",
        "url2 = \"https://www.cs.cmu.edu/~./enron/\" # Email data from the senior management of Enron that is organized into folders\n",
        "# It contains data from about 150 users, mostly senior management of Enron, The corpus contains a total of about 0.5M messages.\n",
        "\n",
        "url3 = \"https://snap.stanford.edu/data/web-Amazon.html\" # This dataset consists of reviews from amazon.\n",
        "# The data span a period of 18 years, including ~35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plaintext review.\n",
        "\n",
        "url4 = \"http://qwone.com/~jason/20Newsgroups/\" # The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents,\n",
        "# partitioned (nearly) evenly across 20 different newsgroups\n",
        "\n",
        "url5 = \"http://www.cs.jhu.edu/~mdredze/datasets/sentiment/\" # Features product reviews from Amazon.\n",
        "# The Multi-Domain Sentiment Dataset contains product reviews taken from Amazon.com from many product types (domains)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S88AkoMiVxKd"
      },
      "source": [
        "Spatial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68lWQOsOVqv-"
      },
      "source": [
        "url1 = \"https://www.tensorflow.org/datasets/catalog/patch_camelyon\" # The PatchCamelyon benchmark is a new and challenging image classification dataset. \n",
        "# It consists of 327.680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections.\n",
        "# Each image is annoted with a binary label indicating presence of metastatic tissue.\"\n",
        "\n",
        "url2 = \"https://data.mendeley.com/datasets/4drtyfjtfy/1\" # Used for multi-class weather recognition, this dataset is a collection of 1125 images divided into four categories.\n",
        "#  The image categories are sunrise, shine, rain, and cloudy\n",
        "\n",
        "url3 = \"https://www.kaggle.com/itsahmad/indoor-scenes-cvpr-2019\" # From MIT, this dataset contains over 15,000 images of indoor locations. The dataset was originally built to tackle the problem of indoor scene recognition.\n",
        "#  All images are in JPEG format and have been divided into 67 categories\n",
        "\n",
        "url4 = \"https://www.kaggle.com/puneet6060/intel-image-classification/version/2\" # Created by Intel for an image classification contest, this expansive image dataset contains approximately 25,000 images.\n",
        "#  Furthermore, the images are divided into the following categories: buildings, forest, glacier, mountain, sea, and street\n",
        "\n",
        "url5 = \"https://www.tensorflow.org/datasets/catalog/sun397\" # this dataset contains over 108,000 images used in the Scene Understanding (SUN) benchmark. \n",
        "# Furthermore, the images have been divided into 397 categories."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X8MiRkBVEhk"
      },
      "source": [
        "### 2.   Write a python code to input a dataset (csv file) of Discrete datatype, automatically identify and print the\n",
        "\n",
        "    a. Number of attributes and number of data points\n",
        "    \n",
        "    b. Data scale of each attribute\n",
        "    \n",
        "    c. Data value of each attribute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mmvC5KyVEhl"
      },
      "source": [
        "#### Note: The number of categories for categorical (nominal,ordinal) data scale for the evaluating datasets is not greater than 8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg9AV8n7VEhl"
      },
      "source": [
        "def data_description(filename):\n",
        "    ## Write a well commented function that inputs dataset file location (.csv file) and outputs the following\n",
        "    ## 1. data_scale (of length = number of attributes)\n",
        "    ## 2. data_value (of length = number of attributes)\n",
        "    ## 3. imported dataset for later use\n",
        "    ## It should also print those details for each attribute(Output must be similar to what is mentioned below)\n",
        "\n",
        "    #data_description(filename)\n",
        "    df = pd.read_csv(filename)\n",
        "    #display(df)\n",
        "    print(\"This dataset contains %d entries, each with %d attributes\" % (df.shape[0],df.shape[1]))\n",
        "    print()\n",
        "    #print(df['Fide id'].max())\n",
        "    #print(df['Fide id'].nunique()/len(df)) # discrete if <=0.15 \n",
        "    #print(df.dtypes)\n",
        "    #print(df['Rapid_rating'][0].is_integer())\n",
        "\n",
        "    def string_found(list_of_string1, string2):\n",
        "      for string1 in list_of_string1:\n",
        "         if re.search(r\"\\b\" + re.escape(string1) + r\"\\b\", string2, re.IGNORECASE):\n",
        "             return True\n",
        "         return False\n",
        "\n",
        "    data_scales=[]\n",
        "    data_values=[]\n",
        "    for i,col in enumerate(df.columns):\n",
        "      if string_found(['id','gender','name'],col):\n",
        "        data_values.append((i,'discrete'))\n",
        "        data_scales.append((i,'nominal'))\n",
        "      elif (df[col].nunique()/len(df))>0.95:\n",
        "        data_values.append((i,'discrete'))\n",
        "        data_scales.append((i,'nominal'))        \n",
        "      elif ('date' in col.lower()) | ('year' in col.lower()):\n",
        "        data_values.append((i,'discrete'))\n",
        "        data_scales.append((i,'interval')) \n",
        "      elif df[col].dtype == 'object':\n",
        "        data_values.append((i,'discrete'))\n",
        "        data_scales.append((i,'nominal'))    \n",
        "      #elif 'rating' in col.lower():\n",
        "      #  data_values.append((i,'discrete'))\n",
        "       # data_scales.append((i,'ordinal')) \n",
        "      elif ((df[col].nunique()==2)):\n",
        "      #( (df[col].dtype=='float64') | (df[col].dtype=='int64') | (df[col].dtype=='int32'):\n",
        "        data_values.append((i,'discrete'))\n",
        "        data_scales.append((i,'nominal'))     \n",
        "      elif ((df[col].nunique()<=10) & (is_numeric_dtype(df[col]))):\n",
        "      #( (df[col].dtype=='float64') | (df[col].dtype=='int64') | (df[col].dtype=='int32'):\n",
        "        data_values.append((i,'discrete'))\n",
        "        data_scales.append((i,'ordinal')) \n",
        "      elif ((df[col].nunique()<=10)):\n",
        "      #( (df[col].dtype=='float64') | (df[col].dtype=='int64') | (df[col].dtype=='int32'):\n",
        "        data_values.append((i,'discrete'))\n",
        "        data_scales.append((i,'nominal')) \n",
        "      elif (len(df[df['Age']%1==0])==len(df)):\n",
        "        data_values.append((i,'discrete'))\n",
        "        if (df[col] < 0).values.any()):\n",
        "          data_scales.append((i,'interval')) \n",
        "        else:\n",
        "          data_scales.append((i,'ratio'))\n",
        "      elif (is_numeric_dtype(df[col])):\n",
        "        data_values.append((i,'continuous'))\n",
        "        data_scales.append((i,'ratio'))      \n",
        "    data_values.sort(key=lambda tup: tup[0])\n",
        "    data_scales.sort(key=lambda tup: tup[0])\n",
        "\n",
        "    for i,col in enumerate(df.columns):\n",
        "      print('%d %s : %s , %s' % (i,col,data_scales[i][1],data_values[i][1]))\n",
        "        \n",
        "        \n",
        "    return data_scales, data_values, df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmjOBZqzcw2y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "34ef936a-ea6d-4017-c1d9-5cc6d84dc268"
      },
      "source": [
        "filename = \"/content/estonia-passenger-list.csv\"\n",
        "data_scales, data_values, df = data_description(filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This dataset contains 989 entries, each with 8 attributes\n",
            "\n",
            "0 PassengerId : nominal , discrete\n",
            "1 Country : nominal , discrete\n",
            "2 Firstname : nominal , discrete\n",
            "3 Lastname : nominal , discrete\n",
            "4 Sex : nominal , discrete\n",
            "5 Age : ratio , discrete\n",
            "6 Category : nominal , discrete\n",
            "7 Survived : nominal , discrete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DNU8cXqGWS3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "3f989f4b-e9ba-40f4-8883-4c3c97674b22"
      },
      "source": [
        "print(df.head())\n",
        "print(df['PassengerId'].nunique())\n",
        "df.shape[0]\n",
        "print(df['PassengerId'].value_counts())\n",
        "print(len(df[df['Age']%1==0])==len(df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PassengerId  Country        Firstname  Lastname Sex  Age Category  Survived\n",
            "0            1   Sweden      ARVID KALLE     AADLI   M   62        P         0\n",
            "1            2  Estonia              LEA   AALISTE   F   22        C         0\n",
            "2            3  Estonia             AIRI   AAVASTE   F   21        C         0\n",
            "3            4   Sweden             JURI     AAVIK   M   53        C         0\n",
            "4            5   Sweden  BRITTA ELISABET  AHLSTROM   F   55        P         0\n",
            "987\n",
            "463    2\n",
            "767    2\n",
            "989    1\n",
            "338    1\n",
            "336    1\n",
            "      ..\n",
            "654    1\n",
            "653    1\n",
            "652    1\n",
            "651    1\n",
            "1      1\n",
            "Name: PassengerId, Length: 987, dtype: int64\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfEJ0sUHj41n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "12074b3b-f487-4134-ad73-d659e98187a7"
      },
      "source": [
        "df['PassengerId'].mode()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    463\n",
              "1    767\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qRGQygD-SW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "fa587c6c-4ada-4173-ce68-6967a8621f0b"
      },
      "source": [
        "#print(df.loc[df['Blitz_rating']%1==0])\n",
        "#print(df.shape)\n",
        "#print(df.describe())\n",
        "#df2 = df.dropna()\n",
        "#print(df2.describe())\n",
        "for i,col in enumerate(df.columns):\n",
        "  if data_scales[i][1]=='nominal':\n",
        "    print(col)\n",
        "    print(\"Mode %s\" % (str(df[col].mode().values)))\n",
        "    print(df[col].value_counts()[:5])\n",
        "    print()\n",
        "  if data_scales[i][1]=='ordinal':\n",
        "    print(col)\n",
        "    print(\"Median %s\" % (str(df[col].median())))\n",
        "    print(\"Mode %s\" % (str(df[col].mode().values)))\n",
        "    print(df[col].value_counts()[:5])\n",
        "    print()\n",
        "  if data_scales[i][1]=='ordinal':\n",
        "    print(col)\n",
        "    print(\"Median %s\" % (str(df[col].median())))\n",
        "    print(\"Mode %s\" % (str(df[col].mode().values)))\n",
        "    print(df[col].value_counts()[:5])\n",
        "    print()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PassengerId\n",
            "Mode [463 767]\n",
            "463    2\n",
            "767    2\n",
            "989    1\n",
            "338    1\n",
            "336    1\n",
            "Name: PassengerId, dtype: int64\n",
            "\n",
            "Country\n",
            "Mode ['Sweden']\n",
            "Sweden     550\n",
            "Estonia    344\n",
            "Latvia      28\n",
            "Finland     16\n",
            "Russia      14\n",
            "Name: Country, dtype: int64\n",
            "\n",
            "Firstname\n",
            "Mode ['ANDRES' 'RAIVO' 'TIINA']\n",
            "RAIVO     8\n",
            "TIINA     8\n",
            "ANDRES    8\n",
            "PAUL      6\n",
            "KATRIN    6\n",
            "Name: Firstname, dtype: int64\n",
            "\n",
            "Lastname\n",
            "Mode ['ANDERSSON']\n",
            "ANDERSSON    15\n",
            "NILSSON      12\n",
            "ERIKSSON     11\n",
            "KARLSSON      9\n",
            "JOHANSSON     9\n",
            "Name: Lastname, dtype: int64\n",
            "\n",
            "Sex\n",
            "Mode ['M']\n",
            "M    503\n",
            "F    486\n",
            "Name: Sex, dtype: int64\n",
            "\n",
            "Category\n",
            "Mode ['P']\n",
            "P    796\n",
            "C    193\n",
            "Name: Category, dtype: int64\n",
            "\n",
            "Survived\n",
            "Mode [0]\n",
            "0    852\n",
            "1    137\n",
            "Name: Survived, dtype: int64\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5U1gKUIVEho"
      },
      "source": [
        "    Output must similar to this:\n",
        "    \n",
        "    This dataset contains 649 entries, each with 6 attributes\n",
        "\n",
        "    0 gender : nominal, discrete\n",
        "    1 age : ratio, discrete\n",
        "    2 health_rating : ordinal, discrete\n",
        "    3 StudentIQ : ratio, discrete\n",
        "    4 no_of_courses : ratio, discrete\n",
        "    5 Marks : ratio, continuous\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIHHRlYmVEhp"
      },
      "source": [
        "### 3. Write a python code to perform statistics on each data column based on its data scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAjL0ZP2VEhq"
      },
      "source": [
        "def stats(filename):\n",
        "    ## Write a well commented function that calls the function data_description and prints\n",
        "    ## relevant statistics based on data scale.\n",
        "    ## Hint: Explore describe()\n",
        "    \n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbHCZ9x0_x74"
      },
      "source": [
        "stats(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F184ioTKemOa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "4c30496d-54b8-4cbb-e0be-5dc6b6027555"
      },
      "source": [
        "(df.describe().iloc[:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    8.553000e+03\n",
              "mean     8.829011e+06\n",
              "std      9.226777e+06\n",
              "min      1.001450e+05\n",
              "25%      2.119447e+06\n",
              "50%      4.500539e+06\n",
              "75%      1.360553e+07\n",
              "max      7.360114e+07\n",
              "Name: Fide id, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UenfU7nwVEht"
      },
      "source": [
        "    Output must be some what similar to this:\n",
        "\n",
        "    gender\n",
        "    mode F\n",
        "    F    383\n",
        "    M    266\n",
        "    Name: gender, dtype: int64 \n",
        "\n",
        "    age\n",
        "    mode      17.000000\n",
        "    mean      16.744222\n",
        "    std        1.218138\n",
        "    min       15.000000\n",
        "    25%       16.000000\n",
        "    median    17.000000\n",
        "    75%       18.000000\n",
        "    max       22.000000\n",
        "    Name: age, dtype: float64 \n",
        "\n",
        "    health_rating\n",
        "    mode   5\n",
        "    median 4\n",
        "    1     90\n",
        "    2     78\n",
        "    3    124\n",
        "    4    108\n",
        "    5    249\n",
        "    Name: health_rating, dtype: int64 \n",
        "\n",
        "    StudentIQ\n",
        "    mode     104.000000\n",
        "    mean     100.229584\n",
        "    std       10.256494\n",
        "    min       75.000000\n",
        "    25%       93.000000\n",
        "    median   101.000000\n",
        "    75%      107.000000\n",
        "    max      131.000000\n",
        "    Name: StudentIQ, dtype: float64 \n",
        "\n",
        "    no_of_courses\n",
        "    mode      17.000000\n",
        "    count    649.000000\n",
        "    mean      10.596302\n",
        "    std        5.714697\n",
        "    min        1.000000\n",
        "    25%        5.000000\n",
        "    median    11.000000\n",
        "    75%       16.000000\n",
        "    max       20.000000\n",
        "    Name: no_of_courses, dtype: float64 \n",
        "\n",
        "    Marks\n",
        "    mode      52.810000\n",
        "    count    649.000000\n",
        "    mean      75.137257\n",
        "    std       14.559722\n",
        "    min       50.120000\n",
        "    25%       62.560000\n",
        "    median    75.120000\n",
        "    75%       87.670000\n",
        "    max       99.860000\n",
        "    Name: Marks, dtype: float64 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yRwUdK1VEhu"
      },
      "source": [
        "### 4. Can we use a box plot for visualizing ordinal data ? (Yes/No). Explain why.\n",
        "![MicrosoftTeams-image2.png](attachment:MicrosoftTeams-image2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkuVd-1GVEhu"
      },
      "source": [
        "### Write your answer here. \n",
        "    YES/NO Because"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNY0HQazVEhv"
      },
      "source": [
        "###   5.  Write a python code to visualize the data (a generalized method depending on data scale) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3wclINqVEhv"
      },
      "source": [
        "def visualize_data(filename):\n",
        "        ## Write a well commented function that can call any of the functions from above \n",
        "        ## to plot relevant plots\n",
        "        ## Hint: Use sns.distplot, sns.countplot. Make a new figure for each plot (plt.figure(i))\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}